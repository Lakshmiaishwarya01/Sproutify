
import os
import io
import time
import pickle
import numpy as np
import pandas as pd

# sklearn imports
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Firebase (optional)
import firebase_admin
from firebase_admin import credentials, db

# Colab file helpers (optional)
try:
    from google.colab import files
    _COLAB_AVAILABLE = True
except Exception:
    _COLAB_AVAILABLE = False

# ---------------------------
# Part 1: Firebase utilities
# ---------------------------
def setup_firebase(service_account_path=None, database_url=None):
    """
    Initialize Firebase Realtime Database connection.
    - In Colab, if service_account_path is None, prompts an upload.
    - If not using Firebase, return False and program will continue in offline mode.
    """
    if database_url is None:
        database_url = 'https://sproutify-3a23c-default-rtdb.asia-southeast1.firebasedatabase.app'

    try:
        # If already initialized, do nothing
        try:
            firebase_admin.get_app()
            print("Firebase already initialized.")
            return True
        except ValueError:
            pass

        if service_account_path is None and _COLAB_AVAILABLE:
            print("Please upload your Firebase service account JSON file (Colab):")
            uploaded = files.upload()
            service_account_path = list(uploaded.keys())[0]

        if service_account_path is None:
            print("No Firebase service account provided. Continuing without Firebase.")
            return False

        cred = credentials.Certificate(service_account_path)
        firebase_admin.initialize_app(cred, {'databaseURL': database_url})
        print("Firebase initialized.")
        return True

    except Exception as e:
        print("Error initializing Firebase:", e)
        return False

# ---------------------------
# Part 2: Data loading & preprocessing
# ---------------------------
def load_data_colab_prompt():
    """Prompt for two CSV files in Colab and return DataFrames (MoneyPlant, WaterLily)."""
    if not _COLAB_AVAILABLE:
        raise RuntimeError("Colab upload not available. Use load_data_from_paths() instead.")
    print("Upload Money Plant CSV:")
    uploaded = files.upload()
    mp_file = list(uploaded.keys())[0]
    money_plant_df = pd.read_csv(io.BytesIO(uploaded[mp_file]))

    print("Upload Water Lily CSV:")
    uploaded = files.upload()
    wl_file = list(uploaded.keys())[0]
    water_lily_df = pd.read_csv(io.BytesIO(uploaded[wl_file]))

    return money_plant_df, water_lily_df

def load_data_from_paths(money_path, water_path):
    """Load local CSV files (non-Colab)."""
    money_plant_df = pd.read_csv(money_path)
    water_lily_df = pd.read_csv(water_path)
    return money_plant_df, water_lily_df

def standardize_columns(df):
    """
    Map common column name variants to standardized names:
    'Soil Moisture', 'Temperature', 'Soil Humidity', 'Nitrogen', 'Phosphorus', 'Potassium'
    Missing columns are filled with zeros.
    """
    mapping_candidates = {
        # Soil moisture variants
        'Soil Moisture': 'Soil Moisture',
        'soil moisture': 'Soil Moisture',
        'SoilMoisture': 'Soil Moisture',
        'Moisture': 'Soil Moisture',
        'moisture': 'Soil Moisture',
        # Temperature variants
        'Temperature': 'Temperature',
        'temperature': 'Temperature',
        'Temp': 'Temperature',
        'temp': 'Temperature',
        # Humidity variants
        'Soil Humidity': 'Soil Humidity',
        'soil humidity': 'Soil Humidity',
        'SoilHumidity': 'Soil Humidity',
        'Humidity': 'Soil Humidity',
        'humidity': 'Soil Humidity',
        # Nitrogen
        'Nitrogen': 'Nitrogen',
        'nitrogen': 'Nitrogen',
        'N': 'Nitrogen',
        # Phosphorus
        'Phosphorus': 'Phosphorus',
        'phosphorus': 'Phosphorus',
        'P': 'Phosphorus',
        # Potassium
        'Potassium': 'Potassium',
        'potassium': 'Potassium',
        'K': 'Potassium'
    }

    standardized = pd.DataFrame(index=df.index)
    std_cols = ['Soil Moisture', 'Temperature', 'Soil Humidity', 'Nitrogen', 'Phosphorus', 'Potassium']
    for std_col in std_cols:
        found = False
        for orig, mapped in mapping_candidates.items():
            if mapped == std_col and orig in df.columns:
                standardized[std_col] = pd.to_numeric(df[orig], errors='coerce')
                found = True
                break
        if not found:
            print(f"[Warning] Column for '{std_col}' not found. Filling with zeros.")
            standardized[std_col] = 0

    # Fill missing numeric values with median
    if standardized.isnull().sum().sum() > 0:
        standardized = standardized.fillna(standardized.median())

    return standardized

def create_targets(df):
    """
    Create binary targets:
    - Action_Water: 1 if Soil Moisture < 30 else 0
    - Action_Nutrient: 1 if any of N,P,K < 40 else 0
    """
    df = df.copy()
    df['Action_Water'] = (df['Soil Moisture'] < 30).astype(int)
    df['Action_Nutrient'] = ((df['Nitrogen'] < 40) |
                             (df['Phosphorus'] < 40) |
                             (df['Potassium'] < 40)).astype(int)
    return df

def preprocess_for_training(df, test_size=0.2, random_state=42):
    """
    Full preprocess pipeline for a single plant dataset.
    Returns scaled train/test splits, y targets, and scaler.
    """
    std_df = standardize_columns(df)
    std_df = create_targets(std_df)

    X = std_df[['Soil Moisture', 'Temperature', 'Soil Humidity', 'Nitrogen', 'Phosphorus', 'Potassium']]
    y_water = std_df['Action_Water']
    y_nutrient = std_df['Action_Nutrient']

    X_train, X_test, y_water_train, y_water_test, y_nutrient_train, y_nutrient_test = train_test_split(
        X, y_water, y_nutrient, test_size=test_size, random_state=random_state
    )

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    return (X_train_scaled, X_test_scaled,
            y_water_train, y_water_test,
            y_nutrient_train, y_nutrient_test,
            scaler)

# ---------------------------
# Part 3: Model training & evaluation
# ---------------------------
def train_models(money_plant_df, water_lily_df, classifier=None):
    """
    Train Logistic Regression models for both plants' water & nutrient decisions.
    Returns dicts: models and scalers.
    """
    if classifier is None:
        classifier = LogisticRegression(max_iter=1000)

    models = {}
    scalers = {}

    # Money plant
    print("\n=== Training Money Plant Models ===")
    (Xtr, Xte, ywtr, ywte, yntr, ynte, scaler_mp) = preprocess_for_training(money_plant_df)
    water_clf = LogisticRegression(max_iter=1000)
    water_clf.fit(Xtr, ywtr)
    yw_pred = water_clf.predict(Xte)
    print("MoneyPlant Water - acc {:.4f} prec {:.4f} rec {:.4f} f1 {:.4f}".format(
        accuracy_score(ywte, yw_pred),
        precision_score(ywte, yw_pred, zero_division=0),
        recall_score(ywte, yw_pred, zero_division=0),
        f1_score(ywte, yw_pred, zero_division=0)
    ))

    nutrient_clf = LogisticRegression(max_iter=1000)
    nutrient_clf.fit(Xtr, yntr)
    yn_pred = nutrient_clf.predict(Xte)
    print("MoneyPlant Nutrient - acc {:.4f} prec {:.4f} rec {:.4f} f1 {:.4f}".format(
        accuracy_score(ynte, yn_pred),
        precision_score(ynte, yn_pred, zero_division=0),
        recall_score(ynte, yn_pred, zero_division=0),
        f1_score(ynte, yn_pred, zero_division=0)
    ))

    models['money_plant_water'] = water_clf
    models['money_plant_nutrient'] = nutrient_clf
    scalers['money_plant'] = scaler_mp

    # Water lily
    print("\n=== Training Water Lily Models ===")
    (Xtr_wl, Xte_wl, ywtr_wl, ywte_wl, yntr_wl, ynte_wl, scaler_wl) = preprocess_for_training(water_lily_df)
    water_clf_wl = LogisticRegression(max_iter=1000)
    water_clf_wl.fit(Xtr_wl, ywtr_wl)
    yw_pred_wl = water_clf_wl.predict(Xte_wl)
    print("WaterLily Water - acc {:.4f} prec {:.4f} rec {:.4f} f1 {:.4f}".format(
        accuracy_score(ywte_wl, yw_pred_wl),
        precision_score(ywte_wl, yw_pred_wl, zero_division=0),
        recall_score(ywte_wl, yw_pred_wl, zero_division=0),
        f1_score(ywte_wl, yw_pred_wl, zero_division=0)
    ))

    nutrient_clf_wl = LogisticRegression(max_iter=1000)
    nutrient_clf_wl.fit(Xtr_wl, yntr_wl)
    yn_pred_wl = nutrient_clf_wl.predict(Xte_wl)
    print("WaterLily Nutrient - acc {:.4f} prec {:.4f} rec {:.4f} f1 {:.4f}".format(
        accuracy_score(ynte_wl, yn_pred_wl),
        precision_score(ynte_wl, yn_pred_wl, zero_division=0),
        recall_score(ynte_wl, yn_pred_wl, zero_division=0),
        f1_score(ynte_wl, yn_pred_wl, zero_division=0)
    ))

    models['water_lily_water'] = water_clf_wl
    models['water_lily_nutrient'] = nutrient_clf_wl
    scalers['water_lily'] = scaler_wl

    return models, scalers

# ---------------------------
# Part 4: Save / load
# ---------------------------
def save_models_and_scalers(models, scalers, out_dir='models'):
    os.makedirs(out_dir, exist_ok=True)
    for name, mdl in models.items():
        path = os.path.join(out_dir, f"{name}.pkl")
        with open(path, 'wb') as f:
            pickle.dump(mdl, f)
        print("Saved model:", path)
    for name, s in scalers.items():
        path = os.path.join(out_dir, f"{name}_scaler.pkl")
        with open(path, 'wb') as f:
            pickle.dump(s, f)
        print("Saved scaler:", path)

def load_models_and_scalers(out_dir='models'):
    models = {}
    scalers = {}
    try:
        models['money_plant_water'] = pickle.load(open(os.path.join(out_dir, 'money_plant_water.pkl'), 'rb'))
        models['money_plant_nutrient'] = pickle.load(open(os.path.join(out_dir, 'money_plant_nutrient.pkl'), 'rb'))
        models['water_lily_water'] = pickle.load(open(os.path.join(out_dir, 'water_lily_water.pkl'), 'rb'))
        models['water_lily_nutrient'] = pickle.load(open(os.path.join(out_dir, 'water_lily_nutrient.pkl'), 'rb'))

        scalers['money_plant'] = pickle.load(open(os.path.join(out_dir, 'money_plant_scaler.pkl'), 'rb'))
        scalers['water_lily'] = pickle.load(open(os.path.join(out_dir, 'water_lily_scaler.pkl'), 'rb'))
        print("Loaded models and scalers from", out_dir)
        return models, scalers
    except Exception as e:
        print("Error loading models/scalers:", e)
        return None, None

# ---------------------------
# Part 5: Prediction & control
# ---------------------------
def _safe_numeric(val, default=0.0):
    try:
        if val is None:
            return float(default)
        return float(val)
    except Exception:
        try:
            return float(str(val).strip())
        except Exception:
            return float(default)

def get_sensor_data_from_firebase():
    """
    Read sensor data from Firebase. Returns two dicts (money_plant_features, water_lily_features).
    If Firebase not configured or data missing, returns (None, None).
    """
    try:
        mp_ref = db.reference('sensors/moneyPlant')
        wl_ref = db.reference('sensors/waterLily')
        n_ref = db.reference('sensors/Nitrogen')
        p_ref = db.reference('sensors/Phosphorus')
        k_ref = db.reference('sensors/Potassium')

        mp_data = mp_ref.get() or {}
        wl_data = wl_ref.get() or {}

        n_value = _safe_numeric(n_ref.get(), 0)
        p_value = _safe_numeric(p_ref.get(), 0)
        k_value = _safe_numeric(k_ref.get(), 0)

        def find_field(d, candidates, default=0):
            for c in candidates:
                if c in d:
                    return _safe_numeric(d.get(c), default)
            return default

        mp_moisture = find_field(mp_data, ['moisture', 'Moisture', 'SoilMoisture', 'Soil Moisture'])
        wl_moisture = find_field(wl_data, ['moisture', 'Moisture', 'SoilMoisture', 'Soil Moisture'])

        mp_temp = find_field(mp_data, ['temperature', 'Temperature', 'Temp', 'temp'])
        wl_temp = find_field(wl_data, ['temperature', 'Temperature', 'Temp', 'temp'])

        mp_humid = find_field(mp_data, ['humidity', 'Humidity', 'SoilHumidity', 'Soil Humidity'])
        wl_humid = find_field(wl_data, ['humidity', 'Humidity', 'SoilHumidity', 'Soil Humidity'])

        money_plant_features = {
            'Soil Moisture': mp_moisture,
            'Temperature': mp_temp,
            'Soil Humidity': mp_humid,
            'Nitrogen': n_value,
            'Phosphorus': p_value,
            'Potassium': k_value
        }

        water_lily_features = {
            'Soil Moisture': wl_moisture,
            'Temperature': wl_temp,
            'Soil Humidity': wl_humid,
            'Nitrogen': n_value,
            'Phosphorus': p_value,
            'Potassium': k_value
        }

        return money_plant_features, water_lily_features

    except Exception as e:
        print("Error reading Firebase sensor data:", e)
        return None, None

def make_predictions(models, scalers, mp_features, wl_features, prob_threshold=0.5):
    """
    Predict using trained models + apply safety threshold overrides.
    Returns (mp_water_final, mp_nutrient_final, wl_water_final, wl_nutrient_final)
    """
    try:
        mp_input = np.array([[mp_features['Soil Moisture'], mp_features['Temperature'],
                              mp_features['Soil Humidity'], mp_features['Nitrogen'],
                              mp_features['Phosphorus'], mp_features['Potassium']]], dtype=float)
        wl_input = np.array([[wl_features['Soil Moisture'], wl_features['Temperature'],
                              wl_features['Soil Humidity'], wl_features['Nitrogen'],
                              wl_features['Phosphorus'], wl_features['Potassium']]], dtype=float)

        mp_scaled = scalers['money_plant'].transform(mp_input)
        wl_scaled = scalers['water_lily'].transform(wl_input)

        # predict_proba returns [[prob_class0, prob_class1]]
        mp_water_prob = models['money_plant_water'].predict_proba(mp_scaled)[0][1]
        mp_nutrient_prob = models['money_plant_nutrient'].predict_proba(mp_scaled)[0][1]
        wl_water_prob = models['water_lily_water'].predict_proba(wl_scaled)[0][1]
        wl_nutrient_prob = models['water_lily_nutrient'].predict_proba(wl_scaled)[0][1]

        mp_water_model = 1 if mp_water_prob > prob_threshold else 0
        mp_nutrient_model = 1 if mp_nutrient_prob > prob_threshold else 0
        wl_water_model = 1 if wl_water_prob > prob_threshold else 0
        wl_nutrient_model = 1 if wl_nutrient_prob > prob_threshold else 0

        # Safety overrides (always allowed to force ON for safety)
        mp_water_override = 1 if mp_features['Soil Moisture'] < 30 else 0
        wl_water_override = 1 if wl_features['Soil Moisture'] < 30 else 0

        mp_nutrient_override = 1 if (mp_features['Nitrogen'] < 40 or
                                     mp_features['Phosphorus'] < 40 or
                                     mp_features['Potassium'] < 40) else 0

        wl_nutrient_override = 1 if (wl_features['Nitrogen'] < 40 or
                                     wl_features['Phosphorus'] < 40 or
                                     wl_features['Potassium'] < 40) else 0

        mp_water_final = int(mp_water_model or mp_water_override)
        mp_nutrient_final = int(mp_nutrient_model or mp_nutrient_override)
        wl_water_final = int(wl_water_model or wl_water_override)
        wl_nutrient_final = int(wl_nutrient_model or wl_nutrient_override)

        # Logging (brief)
        print("\nPredictions (probabilities):")
        print(f"MP water: {mp_water_prob:.3f} -> model {mp_water_model} override {mp_water_override} final {mp_water_final}")
        print(f"MP nutrient: {mp_nutrient_prob:.3f} -> model {mp_nutrient_model} override {mp_nutrient_override} final {mp_nutrient_final}")
        print(f"WL water: {wl_water_prob:.3f} -> model {wl_water_model} override {wl_water_override} final {wl_water_final}")
        print(f"WL nutrient: {wl_nutrient_prob:.3f} -> model {wl_nutrient_model} override {wl_nutrient_override} final {wl_nutrient_final}")

        return mp_water_final, mp_nutrient_final, wl_water_final, wl_nutrient_final

    except Exception as e:
        print("Error in make_predictions:", e)
        return 0, 0, 0, 0

def update_pump_controls(mp_water, mp_nutrient, wl_water, wl_nutrient):
    """
    Update pump control values in Firebase under 'PumpControl' and record predictions under 'predictions'.
    If Firebase not configured, this will print actions.
    """
    try:
        mp_ref = db.reference('PumpControl/moneyPlant')
        mp_ref.update({'Pump1': int(mp_nutrient), 'Pump2': int(mp_water)})

        wl_ref = db.reference('PumpControl/waterLily')
        wl_ref.update({'Pump3': int(wl_water), 'Pump4': int(wl_nutrient)})

        pred_ref = db.reference('predictions')
        pred_ref.update({
            'moneyPlant_water': int(mp_water),
            'moneyPlant_nutrient': int(mp_nutrient),
            'waterLily_water': int(wl_water),
            'waterLily_nutrient': int(wl_nutrient),
            'timestamp': int(time.time())
        })

        print("Pump controls updated in Firebase.")
        return True

    except Exception as e:
        print("Firebase update error (printing instead):", e)
        print(f"MoneyPlant -> Water:{mp_water} Nutrient:{mp_nutrient}")
        print(f"WaterLily  -> Water:{wl_water} Nutrient:{wl_nutrient}")
        return False

# ---------------------------
# Part 6: Runners
# ---------------------------
def run_once_predict_and_update(models, scalers):
    """Run a single cycle: read Firebase, predict, update pumps."""
    mp_features, wl_features = get_sensor_data_from_firebase()
    if not (mp_features and wl_features):
        print("No sensor data available.")
        return
    print("Sensor values:", mp_features, wl_features)
    decisions = make_predictions(models, scalers, mp_features, wl_features)
    update_pump_controls(*decisions)

def run_prediction_loop(models, scalers, interval=300):
    """Continuous loop: read firebase -> predict -> update -> sleep."""
    print(f"Starting continuous prediction loop (interval {interval}s). Ctrl+C to stop.")
    try:
        while True:
            mp_features, wl_features = get_sensor_data_from_firebase()
            if mp_features and wl_features:
                decisions = make_predictions(models, scalers, mp_features, wl_features)
                update_pump_controls(*decisions)
            else:
                print("Sensor data missing; skipping this cycle.")
            time.sleep(interval)
    except KeyboardInterrupt:
        print("Prediction loop stopped by user.")

# ---------------------------
# Part 7: Main CLI-like flow
# ---------------------------
def main():
    print("=== SMART GARDEN ML (Logistic Regression) ===")
    print("1) Setup Firebase? (y/n)")
    use_fb = input().strip().lower() == 'y'
    if use_fb:
        print("If running in Colab, you will be prompted to upload service account JSON.")
        setup_firebase()

    print("\nDo you want to (1) Train models or (2) Load models and run single prediction? Enter 1 or 2:")
    choice = input().strip()
    if choice == '1':
        # Training flow
        if _COLAB_AVAILABLE:
            print("Loading training CSVs via Colab upload. If you are not in Colab, choose load_data_from_paths.")
            money_df, water_df = load_data_colab_prompt()
        else:
            print("Enter path to Money Plant CSV:")
            mp_path = input().strip()
            print("Enter path to Water Lily CSV:")
            wl_path = input().strip()
            money_df, water_df = load_data_from_paths(mp_path, wl_path)

        models, scalers = train_models(money_df, water_df)
        save_models_and_scalers(models, scalers, out_dir='models')
        print("Training complete. You can now run predictions (option 2).")

    elif choice == '2':
        # Load models
        models, scalers = load_models_and_scalers(out_dir='models')
        if models is None:
            print("No models available. Please train first.")
            return

        print("Run (1) single prediction cycle, (2) continuous loop? Enter 1 or 2:")
        r = input().strip()
        if r == '1':
            run_once_predict_and_update(models, scalers)
        else:
            print("Enter interval between checks (seconds), default 300:")
            try:
                interval = int(input().strip() or 300)
            except Exception:
                interval = 300
            run_prediction_loop(models, scalers, interval=interval)
    else:
        print("Goodbye.")

if _name_ == "_main_":
    main()
